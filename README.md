# Hyperbolic Insights With Knowledge Distillation for Cross-Domain Few-Shot Learning

https://ieeexplore.ieee.org/abstract/document/10938027

Xi Yang<sup>1</sup>, Dechen Kong<sup>1</sup>, Nannan Wang Yin<sup>1</sup>, Xinbo Gao<sup>2*</sup>

<sup>*</sup>Corresponding author.

**IEEE TIP**

## Introduction
 we introduce Hyperbolic Insights with Knowledge Distillation (HIDK). This model facilitates feature transformation from Euclidean space to the PoincarÂ´ e ball via hyperbolic mapping. During the meta-learning phase, it
 establishes a unified description of multi-domain features in hyperbolic space through hyperbolic fitting distillation. However, to address notable disparities between the in distribution domain and out-of-distribution domain, we employ a hyperbolic adaptive module to bridge the gap during the meta-testing phase.



## Dependency
To run this project, the following dependencies need to be installed.
- python - 3.8.0
- pytorch - 1.12.1
- hyptorch - 1.0.0 
- numpy   - 1.21.5 
- cudatoolkit  - 11.3.1
- tensorflow-gpu  - 2.2.0 
